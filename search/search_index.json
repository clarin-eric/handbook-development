{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#about-the-handbook","title":"About the handbook","text":"<p>This is work in progress!</p> <p>[TODO]</p>"},{"location":"#contributing-to-the-handbook","title":"Contributing to the handbook","text":"<p>Please read and follow the meta guidelines!</p> <p>For further instructions, see the GitHub repository.</p> <p></p>"},{"location":"meta-guidelines/","title":"Meta guidelines","text":"<p>This section presents some guidelines for the writing and maintenance of this handbook.</p>"},{"location":"meta-guidelines/#scope","title":"Scope","text":"<p>The development handbook is aimed to give guidelines and best practices for the development process. Strictly operational matters should be avoided here, and rather be included in the operational handbook.</p> <p>As a rule of thumb, the following distinction can be kept in mind:</p> <ul> <li>\ud83d\udc49 Anything that (also) happens on your local machine <code>SHOULD</code> be done in   line with the development handbook.</li> <li>\ud83d\udc49 Anything that (also) happens in the infrastructure (in a broad sense?),   or where roles &amp; responsibilities come into play,   <code>SHOULD</code> be done according to the operational handbook.</li> </ul> <p>Note that most processes involve both development and operational aspects.</p>"},{"location":"meta-guidelines/#structure","title":"Structure","text":"<ul> <li>\ud83d\udc49 Each page <code>MUST</code> have a level 1 heading (<code>#</code>) for the title of the section   or chapter</li> <li>\ud83d\udc49 Level 2 headings (<code>##</code>) <code>MUST</code> be used for the main sections and use lower   level headings for subsections</li> <li>\ud83d\udc49 Each page <code>SHOULD</code> include a short introduction describing its scope and context</li> </ul>"},{"location":"meta-guidelines/#style","title":"Style","text":"<ul> <li>\ud83d\udc49 Mark concrete guidelines with the \ud83d\udc49 emoji</li> <li>{TODO: Marking of policies, hints?}</li> <li>\ud83d\udc49 Sets of related guidelines <code>SHOULD</code> be enumerated using unordered lists   (as used here)</li> <li>\ud83d\udc49 Important keywords <code>MAY</code> be highlighted using <code>**</code> emphasis markup</li> <li>\ud83d\udc49 Use <code>MAY</code>, <code>SHOULD</code> and <code>MUST</code> and use code markup for these using backticks</li> <li>\ud83d\udc49 References <code>SHOULD</code> be placed in footnotes. Use the footnote markup that is   supported in both GitHub and mkdocs via the footnotes plugin, and requires usage   of a specific syntax1.</li> <li>\ud83d\udc49 Links that are not references <code>MAY</code> be rendered as regular inline links (see   below for an example)</li> <li>\ud83d\udc49 The markdown for each page <code>MUST</code> pass linting with   markdownlint (see rules2).</li> <li>TODO: hint about CI and local linting</li> </ul>"},{"location":"meta-guidelines/#content","title":"Content","text":"<ul> <li>\ud83d\udc49 References to information sources and other relevant related resources <code>SHOULD</code>   be included where applicable. Use footnotes as described above.</li> </ul> <ol> <li> <p>GitHub blog: \"Footnotes now supported in Markdown fields\" \u21a9</p> </li> <li> <p>Markdownlint repository: <code>docs/RULES.md</code> \u21a9</p> </li> </ol>"},{"location":"general-guidelines/api/","title":"API","text":""},{"location":"general-guidelines/code-licencing/","title":"Code licence","text":"<ul> <li>Each code (including docker image/compose) or documentation project MUST be explicitly licenced</li> <li>Git repositories should have a LICENCE file if a single licence applies to the entire repo</li> <li>Docker: see below</li> <li>Default licence (see also \u200b\u200bhttps://www.clarin.eu/programmers):</li> <li>For code: GPLv3 [Policy]<ul> <li>Exception: if not compatible with libraries or other context</li> <li>Includes bundled documentation (readme, change log etc)</li> </ul> </li> <li>For documentation projects: CC0<ul> <li>e.g. https://github.com/clarin-eric/cereal</li> <li>Put licence statement in footer of document itself<ul> <li>Note: in some cases (e.g. GPL??) licence itself must also be bundled</li> </ul> </li> </ul> </li> <li>Tooling</li> <li>https://www.fossology.org/</li> <li>Licence compliance<ul> <li>e.g. maven licence plugin</li> <li>GitHub community standards check</li> </ul> </li> <li>Licence compatibility<ul> <li>check for conflicting licences<ul> <li>https://dwheeler.com/essays/floss-license-slide.html</li> </ul> </li> </ul> </li> </ul>"},{"location":"general-guidelines/code-licencing/#docker-image-repositories","title":"Docker image repositories","text":"<p>For docker images, we generally publish code (the Dockerfile itself, scripts, configuration files, CI configuration, etc) for images under a GPL3 licence (see above). However we typically also openly distribute the built image via a GitLab container registry. In this approach, there is no straightforward way of attaching a licence or terms of use to an image. To mitigate this, we include a statement in the repository regarding the responsibility in terms of use and redistribution of the image in its built form. See the Docker section of this handbook for the exact guideline.</p> <p>---------------------8&lt;----------------- For the Docker section -----------------------------------------</p> <p>For images that are deployed to a public container registry (i.e. submitted to the GitLab container registry typically via a CI job which is the case for virtually all of our central infrastructure images):</p> <ul> <li> <p>Create a file README.legal.txt based on the following template:</p> <p>View the [licence information](LICENSE.md) for the source code used to build this image.</p> <p> View the [licence information]() for the software included in this image. </p> <p>An image built from the sources in this repository is distributed by CLARIN. As with all Docker images, this likely also contains other software which may be under other licences (such as Bash, etc from the base distribution, along with any direct or indirect dependencies of the primary software being contained).</p> <p>As for any pre-built image usage, it is the image user's responsibility to ensure that any use of this image complies with any relevant licences for all software contained within.</p> </li> <li> <p>Add a reference to README.legal.txt to the README file of the repository, e.g. in a section titled \u2018Licence\u2019.</p> </li> <li>Add the README.legal.txt file (???) to the root of the image\u2019s file system (i.e. COPY that file into the image via the Dockerfile).\u00a0 Add a symbolic link from the WORKDIR.</li> <li>Also copy the LICENSE.md file to the root of the image\u2019s file system</li> </ul> <p>----------------------------------------- For the Docker section -----------------------------&gt;8---------</p>"},{"location":"general-guidelines/code-lifecycle/","title":"Code lifecycle","text":"<p>{TODO: introduction}</p>"},{"location":"general-guidelines/code-lifecycle/#version-numbering","title":"Version numbering","text":"<p>\ud83d\udc49 The format that version numbers <code>SHOULD</code> adhere to is <code>major.minor.patch[-qualifier]</code> where:</p> <ul> <li><code>major</code>, <code>minor</code> and <code>patch</code> <code>SHOULD</code> be integers, and</li> <li>the optional <code>qualifier</code>, if included, <code>SHOULD</code> be either <code>test</code>, <code>alpha</code>,   <code>beta</code> or <code>RC</code>, followed by an integer, OR a string such as <code>dev</code>, <code>SNAPSHOT</code>   [in case of work in progress].</li> </ul> <p>Examples:</p> <ul> <li>Examples of valid version numbers without qualifiers: <code>1.0.0</code>, <code>4.11.2</code></li> <li>Examples of valid version numbers with qualifiers: <code>3.0.1-alpha1</code>, <code>8.6.0-RC2</code>,   <code>2.5.0-SNAPSHOT</code></li> <li>Examples of invalid version numbers: <code>1.0</code>, <code>2-alpha1</code>, <code>3.1.0-beta</code></li> </ul> <p>\ud83d\udc49 Commit id (git hash) <code>SHOULD NOT</code> be used in the version number. It is good practice is to include it somewhere in the built application (\"About\" page and/or manifest file).</p>"},{"location":"general-guidelines/code-lifecycle/#scope","title":"Scope","text":"<p>\ud83d\udc49 Version numbers <code>SHOULD</code> be aligned for projects that are maintained in the same repository and share a release pipeline (e.g. modules of an application)</p> <p>\ud83d\udc49 Version numbers <code>SHOULD</code> be decoupled for projects that are released separately and/or are maintained in separate repositories.</p>"},{"location":"general-guidelines/code-lifecycle/#increasing-version-numbers","title":"Increasing version numbers","text":"<p>\ud83d\udc49 When releasing a new version of a software component or other project, one of the version components <code>SHOULD</code> be increased (major, minor, patch or qualifier), typically by <code>+1</code>.</p> <p>\ud83d\udc49 Semantic versioning <code>SHOULD</code> be applied in the case of libraries and shared APIs as described at semver.org. More on versioning of APIs in the API section of the handbook.</p> <p>Regarding version number increases, the following guidelines are to be considered:</p> <ul> <li>\ud83d\udc49 The major version number <code>SHOULD</code> be increased</li> <li>for major revisions affecting all or most features, or most of the      user interface;</li> <li>if significant features changed or reimplemented fundamentally,      or removed;</li> <li>if compatibility with existing configurations is broken;</li> <li>if public access paths (i.e. URLs) have changed in an incompatible way.</li> <li>\ud83d\udc49 The minor version number <code>SHOULD</code> be increased</li> <li>when new features have been added;</li> <li>when the underlying framework or other core dependencies have had a major   version upgrade.</li> <li>\ud83d\udc49 The patch level version number <code>SHOULD</code> be increased</li> <li>for bug fixes and small improvements to existing features;</li> <li>for minor dependency upgrades;</li> <li>for any other kind of maintenance that does not affect functionality or      compatibility.</li> <li>\ud83d\udc49 The qualifier can be increased at any point during alpha, beta and release   candidate development stages. For stable releases, it must be excluded altogether.</li> </ul>"},{"location":"general-guidelines/code-lifecycle/#releasing","title":"Releasing","text":""},{"location":"general-guidelines/code-lifecycle/#lifecycle-stages","title":"Lifecycle stages","text":"<p>\ud83d\udc49 The release process <code>SHOULD</code> be broken up into the following stages. Promote (or demote) according to the descriptions below. The version number (and therefore tag) <code>SHOULD</code> reflect the lifecycle stage in the value and/or presence of the qualifier part of the version number.</p> <ul> <li>Alpha: Feature developments</li> <li>Stability and functionality do not have to be guaranteed</li> <li>Dependencies can still change, including updates to new minor versions</li> <li>Alpha status should be clear to the end user in the application's      interface (if applicable)</li> <li>Beta: Feature freeze</li> <li>Bug fixes and feature enhancements</li> <li>Dependency checks, update to latest within minor and apply any      available security updates</li> <li>Version control: branch off from development</li> <li>Beta status should be clear to the end user in the application's      interface (if applicable)</li> <li>Release candidate</li> <li>Bugs are either fixed or documented as known issues</li> <li>Final dependency checks, main focus on security (high and critical      vulnerabilities must be resolved or else documented)</li> <li>Write or finalise a change log and upgrade instructions</li> <li>Release</li> <li>Should be identical to the last release candidate except for the      version number</li> </ul>"},{"location":"general-guidelines/code-lifecycle/#hotfixes","title":"Hotfixes","text":"<p>{TODO}</p>"},{"location":"general-guidelines/code-lifecycle/#publication","title":"Publication","text":"<p>\ud83d\udc49 Make a GitHub or GitLab release for each stable tag.</p> <ul> <li>Specify any major changes in this version</li> <li>If it is a maintenance release, write 'Maintenance release'</li> <li>List major vulnerabilities resolved</li> <li>For images: specify the version of base image os and relevant software packages   (also if not changed)</li> <li>For 'base images': include the relevant platform versions in the title of the   release (e.g. <code>3.18.4 / Java 17.0.9</code>)</li> </ul>"},{"location":"general-guidelines/code-lifecycle/#docker-image-versioning","title":"Docker image versioning","text":"<p>\ud83d\udc49  The following approach <code>SHOULD</code> be followed for application images and <code>MAY</code> be followed for other images that are centred around a specific version of a platform or environment:</p> <ul> <li>Scheme for the version number/tag is <code>{APP_VERSION}_{X.Y.Z}</code> </li> <li>Where <code>{X.Y.Z}</code> is a version that follows the guidlines above and starts with      <code>1.0.0</code> for each new value of <code>{APP_VERSION}</code></li> <li><code>{APP_VERSION}</code> <code>MAY</code> include qualifiers such as <code>alpha1</code>, but <code>{X.Y.Z}</code> <code>SHOULD</code> consist of three dot separated digits only</li> <li><code>{APP_VERSION}</code> <code>MAY</code> be reduced to a significant level such as <code>{major.minor}</code>      or in some cases even just <code>{major}</code></li> <li>Resetting of the image version resets for every app version, so there will be,      for instance, <code>1.0_1.0.0</code>, followed by <code>1.0_2.0.0</code> and <code>1.1_1.0.0</code>.</li> <li>Examples:</li> </ul> App v. Image v. Combined 1.0.0 _ 1.0.0 app-1.0.0_1.0.0 1.1.0-alpha1 _ 1.2.2 app-1.1.0-alpha1_1.2.2 <p>\ud83d\udc49 For base images and other images that provide a platform or 'environment' rather than an application (e.g. alpine, java, tomcat, nginx), version numbering <code>MAY</code> follow the same scheme as applications (<code>major.minor.path[-qualifier]</code>).</p>"},{"location":"general-guidelines/code-lifecycle/#docker-compose-projects","title":"Docker compose projects","text":"<p>\ud83d\udc49 The following approach <code>SHOULD</code> be followed for compose projects:</p> <ul> <li>IFF there is a single application with a single version number it is built   around, follow the same scheme as for application docker images (<code>{APP_VERSION}_{X.Y.Z}</code>)</li> <li>Otherwise use 'independent' version numbering (suite version)</li> <li>Naming of the project typically reflects whether it is application centered or   a 'suite'. In the latter case it has (or could have) a name that is different to   one of the included services.</li> </ul>"},{"location":"general-guidelines/code-lifecycle/#branching-merging-strategies","title":"Branching, merging strategies","text":"<ul> <li> <p>General guidelines on workflow(s)</p> </li> <li> <p>Default choice: Git Flow</p> </li> <li>Stages (active development/out of development/deprecated)<ul> <li>Projects that go \u2018out of development\u2019 can have their development branch dropped; in this stage, only make hotfixes.<ul> <li>Hotfix should be in hotfix branch (not directly to main)</li> </ul> </li> </ul> </li> <li>Branches</li> <li> <p>The main branch</p> <ul> <li>\\= Stable<ul> <li>Should have tests and checks in successful state (or warning, no fail)</li> </ul> </li> <li>Avoid direct commits to main branch<ul> <li>Use GH/GL repo config to protect main branch</li> </ul> </li> <li>Name: use \u2018main\u2019 for new projects - ok but not necessary to rename in existing projects<ul> <li>Configure your local git client to use \u2018main\u2019 as the default branch when initializing new repositories:     \u00a0 git config --global init.defaultBranch main     (source)</li> </ul> </li> </ul> </li> <li> <p>Development branch(es)</p> <ul> <li>Name: ^dev(elop(ment)?)?$</li> <li>\u201cPermanent\u201d development branch?<ul> <li>Keep ahead of main branch! With merge.</li> </ul> </li> <li>Alpha tags/release can be made from this branch</li> </ul> </li> <li>Feature branches<ul> <li>Naming<ul> <li>Good practice to include issue number(s) if applicable</li> <li>Otherwise as descriptive (but short) as possible</li> </ul> </li> <li>Should branch off directly from the development branch. Do not \u2018stack\u2019</li> <li>Rebase and clean up before merging back into the targeted branch<ul> <li>Don\u2019t force push the feature branch unless it is a private one</li> </ul> </li> <li>Alpha tags/release can be made from this branch</li> </ul> </li> <li>Release branches<ul> <li>Name<ul> <li>release-x.y(.z)</li> </ul> </li> <li>Upon feature freeze</li> <li>Version number in code base changes on this branch (not develop)</li> <li>From here you may tag x.y.z-betaN (also alpha)</li> <li>Bug fixes until ready for x.y.z release</li> <li>Merge into main branch at time of x.y.z release, then tag x.y.z on main branch</li> </ul> </li> <li>Tags</li> <li>Avoid deleting tags<ul> <li>Exception can be to try to avoid usage anywhere</li> <li>Exception can be to immediately clean up after a slip-up</li> <li>In case of image to be removed from container repo<ul> <li>Delete the image from the container repo but keep the tag, adding a description to the release</li> </ul> </li> <li>NEVER remove a tag if there has ever been a deployment based on that tag (whether testing, staging or production)</li> </ul> </li> <li>Re-tagging<ul> <li>Do not re-tag (use same tag name twice) UNLESS<ul> <li>In a private repository</li> <li>Know for sure that it can not have been used anywhere</li> </ul> </li> <li>Never for stable (non alpha, beta or RC)</li> </ul> </li> <li>Examples of tag patterns for application (note: this repeats on the right hand side for\u00a0 docker images, see section X)<ul> <li>Towards release `x.y.z`, normally in this order<ul> <li>alpha release(s): `x.y.z-alphaN`</li> <li>[feature freeze]</li> <li>beta release(s): `x.y.z-betaN`</li> <li>release candidates: `x.y.z-rcN`</li> <li>final release: `x.y.z`</li> </ul> </li> </ul> </li> <li>Pull requests / merge requests (PRs)</li> <li>Good practice to use PRs instead of merging directly in the client, especially if multiple people are actively working on a project</li> <li>Make pull requests on feature branches (&amp; release branches)<ul> <li>preferably pull requests are not made on permanent branches<ul> <li>note: if your branching strategy includes permanent branches other than the main branch (e.g. development), it probably fits to make release branch</li> </ul> </li> </ul> </li> <li>Naming: PR name should describe the change and if applicable a reference to the issue #<ul> <li>in case of feature branches the name of the branch might give this information</li> <li>beware of default behaviour of Git(Hub|Lab) to use last commit message as title</li> </ul> </li> <li>PR acceptance<ul> <li>Tests &amp; checks should all pass<ul> <li>If overriding failed checks, document reason in a comment</li> </ul> </li> <li>Code reviews?<ul> <li>See below</li> <li>Recommended to request review for PR if multiple active contributors</li> </ul> </li> <li>Branch specific requirements</li> </ul> </li> <li>Forks</li> <li>If the sausage making is very ugly, consider doing it in a fork<ul> <li>Examples:<ul> <li>work that is likely to require a lot of rewriting of git history</li> <li>testing</li> <li>experimenting with tags, CI pipeline</li> </ul> </li> <li>Branch in fork with same name as upstream can serve as feature branch - PR must clearly describe the feature</li> </ul> </li> <li>Maintaining multiple versions</li> <li>Keep a permanent branch for older versions that need to be maintained</li> <li>If need be such a branch can be created at any stage</li> <li>Avoid \u2018orphaned\u2019 tags</li> </ul>"},{"location":"general-guidelines/code-lifecycle/#code-reviews","title":"Code reviews","text":"<p>....</p>"},{"location":"general-guidelines/code-lifecycle/#continuous-integration","title":"Continuous integration","text":"<ul> <li>Where?</li> <li>GitLab<ul> <li>Docker builds -&gt; deploy to GitLab (repo) docker registry</li> <li>Docker compose (test stage tested on GitLab; performance benefit of loading of images from registry)</li> <li>Building of GitHub projects on GitLab for full chain Maven -&gt; Image build &amp; deploy to registry</li> <li>Pay attention to artifact size limits</li> </ul> </li> <li>GitHub actions<ul> <li>For application code</li> <li>Can be used to trigger build on GitLab</li> <li>(Theoretically) more portable than Travis</li> </ul> </li> <li>Travis<ul> <li>Guideline: transition to GitHub actions if feasible    -</li> </ul> </li> </ul> <p>Recommended to have all the following stages implemented:</p> <p>Stages</p> <ul> <li>Linting / resource validation</li> <li>Docker files</li> <li>Shell scripts</li> <li>JS</li> <li>CSS</li> <li>XML</li> <li>Python??</li> <li>Compiling / building</li> <li>Testing</li> <li>Application code: unit tests</li> <li>Docker: build script test command (compose based)</li> <li>Docker compose: control script test command</li> <li>Security check/scan</li> <li>Docker (compose): snyk</li> <li>Release</li> <li>Application: deploy artifact to GitHub release</li> <li>Docker: deploy multi-architecture image to repository</li> </ul> <p>Ignoring or skipping (failing) tests:</p> <ul> <li>During development</li> <li>In case of upstream issues that cannot be resolved</li> </ul>"},{"location":"general-guidelines/configuration/","title":"Configuration","text":""},{"location":"general-guidelines/documentation/","title":"Documentation","text":""},{"location":"general-guidelines/documentation/#general","title":"General","text":"<ul> <li>In repository: what to include (depending on project type)</li> <li>Markup format: MD or Asciidoc</li> <li>Location: root of project</li> <li>README (what to include\u2026 template?) [Policy]<ul> <li>Content [Guidelines] - GitHub: Formatting your README<ul> <li>Project name</li> <li>Description</li> <li>Table of Contents (optional)</li> <li>Installation -&gt; INSTALL</li> <li>Usage<ul> <li>Requirements (runtime, dependencies)</li> <li>How to build</li> <li>How to run</li> </ul> </li> <li>Contributing -&gt; CONTRIBUTE</li> <li>Credits</li> <li>License -&gt; LICENSE</li> </ul> </li> </ul> </li> <li>LICENSE [Policy]<ul> <li>See \u2018Code license section\u2019</li> </ul> </li> <li>INSTALL (what to include\u2026 template?)<ul> <li>Content? [Guidelines]</li> </ul> </li> <li>UPGRADE (what to include\u2026 template?)<ul> <li>Content? [Guidelines]</li> </ul> </li> <li>CHANGES / Release notes</li> <li>CONTRIBUTING - GitHub: Setting guidelines for repository contributors<ul> <li>We will make a general contributions guideline to include by default in all projects</li> <li>A custom contributions guideline document can be made, describing:<ul> <li>Pull request policy</li> <li>Issues policy</li> <li>Branching model</li> <li>..</li> </ul> </li> </ul> </li> <li>..</li> </ul>"},{"location":"general-guidelines/documentation/#design-and-project-documentation","title":"Design and project documentation","text":"<ul> <li>Requirements &amp; architecture design</li> <li>Roadmap</li> </ul>"},{"location":"general-guidelines/documentation/#end-user-documentation","title":"End user documentation","text":"<ul> <li>In what cases is it needed?</li> <li>Where</li> <li>Where/how can the user find it</li> <li>Where is it maintained (and how is it integrated)</li> <li>In what format</li> </ul> <p>\u201cStand alone\u201d documentation (in a broad sense, e.g. this handbook) should be published under a CC-BY 4.0 licence (\u201cCreative Commons - Attribution 4.0 International\u201d).</p>"},{"location":"general-guidelines/logging/","title":"Logging","text":"<ul> <li>General</li> <li>Logging best practices???</li> <li>Log levels</li> <li>What goes at what level<ul> <li>Log levels in different ecosystems</li> </ul> </li> <li>Log content</li> <li>Important things &amp; events to log<ul> <li>Tag</li> </ul> </li> <li>Always include context (ideally provided by logging framework); i.e. line number, class &amp; method, relevant exception etc</li> <li>Processability (consider grep, parsing, use in dashboards)</li> <li>Content to avoid in logs<ul> <li>Secrets</li> <li>(Potentially) personal information at &gt;= INFO level<ul> <li>(user)names, IP addresses, e-mail, address, etc</li> <li>CLARIN policy/statement (re GDPR)</li> </ul> </li> <li>Long content (can frameworks help you - formatting options)</li> </ul> </li> <li>Log frameworks</li> <li>See language specific suggestions in section above</li> <li>Prepare for log aggregation: fluent</li> <li>log parsing<ul> <li>Parse at the 'source' (i.e. local fluent config in image)</li> <li>Conventions / vocabulary for field names (with types)<ul> <li>Full message, timestamp, log level, context, ...</li> </ul> </li> <li>Required fields<ul> <li>Include full/original/unparsed message</li> </ul> </li> <li>Recommended fields<ul> <li>Timestamp</li> </ul> </li> </ul> </li> <li>Log configurations</li> <li>Main log level(s) should be configurable<ul> <li>At container level for main process(es) via environment variable(s)</li> </ul> </li> <li>Other logging configuration<ul> <li>Nice if it can be overridden</li> </ul> </li> <li>Special cases</li> <li>Timing<ul> <li>Include unit</li> </ul> </li> <li>Process start/stop</li> <li>Progress</li> <li>Heartbeat</li> <li>...</li> <li>Smells / bad practices</li> <li>Extensive logging for debugging (especially if not cleaned up)</li> <li>Expensive calculations in log messages (especially if not lazy)</li> </ul>"},{"location":"general-guidelines/maintenance/","title":"Maintenance","text":"<p>Project statuses</p> <ul> <li>Prototype</li> <li>Active development</li> <li>Maint</li> <li>Deprecated - deployed</li> <li>Deprecated - undeployed</li> </ul> <p>Label</p> <p>Development</p> <p>Maintenance</p> <p>Deployed</p> <p>Notes</p> <p>A</p> <p>+</p> <p>+</p> <p>-</p> <p>Prototyping to first RC</p> <p>B</p> <p>+</p> <p>+</p> <p>+</p> <p>Matur(ing), in use</p> <p>At least one stable release</p> <p>C</p> <p>-</p> <p>+</p> <p>+</p> <p>Stable, feature frozen</p> <p>D</p> <p>-</p> <p>-</p> <p>+</p> <p>Abandoned, in use</p> <p>E</p> <p>-</p> <p>-</p> <p>-</p> <p>Dead</p> <p>Definitions</p> <ul> <li>Development</li> <li>There is a development roadmap specific to the dev project</li> <li>Has at least one responsible developer assigned</li> <li>Maintenance</li> <li>Has at least one responsible maintainer assigned<ul> <li>Responsible for monitoring code base in terms of vulnerabilities, functional breakages</li> <li>Responsible for addressing (at the very least) critical issues in the code base</li> </ul> </li> <li>Example activities covered<ul> <li>Dependency / base image updates</li> <li>Implement required adaptations to new or changed context (OS, runtime, servlet container, ...)</li> </ul> </li> </ul> <p>Status</p> <p>Project examples</p> <p>A</p> <p>Prototyping - first RC</p> <p>VCR JS widget</p> <p>VLO 5.0</p> <p>DOG</p> <p>B</p> <p>Matur(ing), in use</p> <p>VLO</p> <p>VCR</p> <p>C</p> <p>Stable, feature frozen</p> <p>Switchboard</p> <p>Component Registry</p> <p>Centre Registry</p> <p>OAI-PMH Harvester, viewer</p> <p>RASA</p> <p>D</p> <p>Abandoned, in use</p> <p>SAML-metadata-checker</p> <p>earlier: FCS?</p> <p>E</p> <p>Dead</p> <p>clarin-horizon_drupal_theme</p> <p>[TODO: guidelines matrix for status X aspect]</p> <p>Per project status:</p> <ul> <li>What drives releases?</li> <li>A-B: roadmap</li> <li>C: external factors, e.g. support for underlying technology, fixing of critical bugs and vulnerabilities</li> <li>D-E: n/a</li> <li>Maintainer(s) - tasks and responsibilities</li> <li>A-C MUST address critical security risks</li> <li>CAN address other issues<ul> <li>enhancements and new functionality covered by developer role!</li> </ul> </li> <li>No maintainer (cat D, E) -&gt; operational handbook<ul> <li>Possibility to (temporarily) address as C in short term</li> <li>OR (temporarily) shut down</li> </ul> </li> <li>Repository</li> <li>Cat A-C: MUST be findable in Git repositories</li> <li>D: SHOULD be in Git repository, MAY be in deprecated repository system</li> <li>E: SHOULD be archived</li> <li>Issue reporting &amp; tracking</li> <li>A-B: known issues, envisioned features are documented in issue tracking system by developer/maintainer<ul> <li>may be for C as well but without commitment</li> </ul> </li> <li>A-B-C: maintainer will handle incoming issue reports via repository system</li> <li>D-E: issue reporting is disabled</li> <li>Documentation</li> <li>A: needs to have minimal documentation (needs to be defined) for development, deployment, testing purposes (up-to-date README file)</li> <li>B-C: need to have up-to-date documentation both for development and operational purposes and end users; changelog</li> <li>D-E: documentation needs to include statement about status of project</li> <li>Monitoring -&gt; operational</li> <li>B-C: needs permanent monitoring with alerting, log aggregation to ensure good health</li> <li>D: included in general monitoring to ensure being alive</li> </ul>"},{"location":"general-guidelines/privacy-data-protection/","title":"Privacy and data protection","text":"<p>Include (reference to) terms and conditions in each user facing application: https://www.clarin.eu/content/terms-use-and-disclaimer</p> <p>Recommendations on what kind of user information applications should collect SERVER SIDE:</p> <p>In general store as little as possible.</p> <ul> <li>Username</li> <li>IFF user needs to be identified uniquely; there is some kind of persistent    user specific state/profile</li> <li>Password / token</li> <li>IFF AAI solution is not available/applicable</li> <li>Names</li> <li>IFF prompted (user has full control)</li> <li>Should not be adopted from the IdP</li> <li>email address</li> <li>IFF requirements include communicating to the user via e-mail</li> <li>Note: if username is e-mail address it can be stored as such, but therefore    not recommended</li> <li>Note: EPPN cannot be assumed to be a (working) e-mail address</li> <li>IP address</li> <li>IFF required for white/black listing</li> <li>If possible, securely hashed</li> <li>If possible, anonymized</li> <li>behavioural data (stats)</li> <li>Should be anonymized; use Matomo</li> <li>Trace of actions (e.g. last login or full audit log)<ul> <li>IFF functionality depends on it, and user is informed and/or on opt-in basis</li> </ul> </li> </ul> <p>It must be possible to delete personal data if requested.</p>"},{"location":"general-guidelines/security/","title":"Security","text":""},{"location":"general-guidelines/security/#protection-against-vulnerability-exploitation","title":"Protection against vulnerability exploitation","text":"<p>General guideline: vulnerability checks/scans should be applied regularly (on pushes, on release, while deployed) at code and/or binary levels</p> <p>General guideline: any known vulnerability with HIGH or CRITICAL severity should be looked into and if at all possible available fix(es) should be applied.</p>"},{"location":"general-guidelines/security/#application-code","title":"Application code","text":"<ul> <li>Use up-to-date dependencies</li> <li>Run check (e.g. Maven dependency plugin, npm/pip/.. update commands)</li> <li>Policy for use of unmaintained/unsupported deps??       -</li> <li>Add project to snyk, enable GitHub security scans (Dependabot)</li> <li>Include linting in CI</li> <li>Cover AAI &amp; input validation in unit tests</li> <li>Handle snyk reports:  <li>Sign binaries &amp; packages?</li> <li>Support in package managers</li>"},{"location":"general-guidelines/security/#image-development","title":"Image development","text":"<ul> <li>Use up-to-date base images</li> <li>Use up-to-date build script</li> <li>Run docker security scan and linting in CI</li> <li>When can security scan be skipped/overridden/ignored<ul> <li>Set allow_failure: true in CI yaml config (GitLab)</li> <li>Pressure to get image out (e.g. RC -&gt; stable release)</li> <li>Evaluate + document risk (create ticket)</li> <li>Pipeline conf change to security scan should be immediately reverted in branch or not merged</li> </ul> </li> <li>Run services as users with minimal permissions (do not leave as or set to root)</li> <li>Make such a\u00a0 user in docker file and set it in supervisor config</li> <li>Make configuration files read-only</li> <li>Make application code read-only</li> <li>Verify hash + signatures if available of downloaded binaries</li> <li>Verify signatures of static executed files at runtime if possible</li> <li>e.g. signed hash of python code</li> <li>Sign images??</li> </ul>"},{"location":"general-guidelines/security/#compose-project-development","title":"Compose project development","text":"<ul> <li>Only use images that have been checked for vulnerabilities (i.e. based on recent CLARIN base images)</li> <li>Run security check in CI (not yet implemented)</li> <li>Network configuration</li> <li>Don\u2019t bind host to port if not needed (rarely needed)<ul> <li>Make overlay for development if necessary (rather than commented out lines)</li> </ul> </li> <li>Allow access beyond internal networks only if necessary. Use the \u2018internal\u2019 option of the network configuration, which creates an \u200b\u200bexternally isolated overlay network (see Compose file version 3 reference)<ul> <li>e.g. database containers generally do not need to be able to access anything or be accessed by anything on the internet</li> </ul> </li> <li>Volumes &amp; mounts</li> <li>Don\u2019t mount docker socket into container</li> <li>If possible avoid host mounts<ul> <li>If needed, make read-only</li> <li>If needed, make a specific/minimal as possible</li> <li>Alternative solution: operation within container (e.g. on volume) and pull (copy) out of container or push out</li> <li>If needed for development, define in overlay</li> </ul> </li> </ul>"},{"location":"general-guidelines/testing/","title":"Testing","text":""},{"location":"interoperability-and-portability/authentication-mechanisms/","title":"Authentication mechanisms","text":"<ul> <li>Shibboleth</li> <li>Use library (Java: shhaa filter - https://github.com/clarin-eric/mpgaai)</li> <li>Other cases: depend on headers (taken care of by central proxy)</li> <li>Developing a shibbolized application<ul> <li>Local development: normally it should be sufficient to have swappable auth configuration (e.g. basic auth &amp; saml)</li> <li>Testing<ul> <li>Not easy to test until first deployment in a prepared (by sysops) environment</li> <li>Easiest would be with test environment (sandboxed with IdP and SP, proxy); deployment method is a question<ul> <li>Not available right now!</li> </ul> </li> </ul> </li> </ul> </li> <li>API authentication</li> <li>Browser based API access<ul> <li>UI served from same server - user can authenticate, API can be used through same session</li> </ul> </li> <li>Non-browser based<ul> <li>Token based<ul> <li>Token has to be requested in shibbolized session</li> </ul> </li> </ul> </li> <li>Other auth mechanism</li> <li>Support basic auth for testing, other deployments</li> </ul>"},{"location":"interoperability-and-portability/configuration/","title":"Configuration","text":""},{"location":"interoperability-and-portability/configuration/#what-should-be-configurable-and-how","title":"What should be configurable and how?","text":"<ul> <li>HOWs</li> <li>Config file</li> <li>App specific environment variable</li> <li>Global system property (application inherits)<ul> <li>Potentially with override option</li> </ul> </li> <li>Database</li> <li>External service</li> <li>...</li> <li>User &amp; role management</li> <li>Externalise all user, role, credentials information from code base</li> <li>Normally there is no need for 'real' management of usernames and passwords; standard situation: db or back end service username/password; end users authenticate through SAML</li> <li>Store roles (if applicable) in database, provided management interface</li> <li>Storing passwords in plain text (i.e. not a hash, unencrypted) should be avoided</li> <li>Having a property in the general configuration for e.g. defining admin user ids is an anti-pattern</li> <li>There can be a property to 'bootstrap' users and roles, e.g. a 'master' admin    -</li> </ul>"},{"location":"interoperability-and-portability/configuration/#external-configurability","title":"External configurability","text":"<ul> <li>Means no (re-)build is needed to apply</li> <li>Reloading configuration</li> <li>Hot reloadable preferable (can also be manually triggered through UI)<ul> <li>If application restart is required, make sure that active sessions don't get broken if at all possible - otherwise warn</li> </ul> </li> <li>Docker (compose)</li> <li>Wherever possible, provide defaults<ul> <li>Dockerfile      -</li> <li>Compose YAML file: \"FOO: ${MY_FOO:-default}\"<ul> <li>In .env this allows for optional \"MY_FOO=bar\"</li> </ul> </li> </ul> </li> <li>Mandatory settings without a default<ul> <li>Docker image should also have logic to check for mandatory settings (use init script)</li> <li>Compose YAML file: \"FOO: ${MY_FOO:?err}\" or \"${MY_LOCAL_DIRECTORY:?err}:/path/inside/container\"<ul> <li>See compose file documentation</li> <li>Particularly useful for mandatory volumes/mounts</li> </ul> </li> </ul> </li> </ul>"},{"location":"interoperability-and-portability/configuration/#parameters-vs-files","title":"Parameters vs files","text":"<ul> <li>Aim for lowest complexity</li> <li>Configuration parameters</li> <li>Environment variables</li> <li>Configuration files</li> <li>&amp; docker images<ul> <li>mounting as file vs mount as directory<ul> <li>directory mount preferred as it can be modified without recreating the container</li> </ul> </li> <li>'Core application' configuration &amp; library/util configuration (logging, scheduling, auth, ...)<ul> <li>If one or more aspects of configuration are done through a mount (e.g. logging), configuration of this should be optional, i.e. provide a default</li> <li>You can provide a way of overriding the core application config (that is normally filtered as a template) through a mount</li> </ul> </li> </ul> </li> <li>&amp; compose projects<ul> <li>directory (or optionally file) configurable through .env variable</li> </ul> </li> <li>Loading from external source<ul> <li>e.g. GitHub<ul> <li>Not a preferable method for application configuration, use conventions described above; suitable for other resources such as definitions (e.g. data mappings), display content (e.g. help page and other documentation, headers &amp; footers) etc.</li> <li>Provide a local caching mechanism - don't depend on availability of external resource in real time<ul> <li>use a local copy; e.g. in container environment load resource on container init</li> <li>try to reload if applicable</li> <li>warn if local copy is too old</li> </ul> </li> <li>Do a validation after retrieval/refresh, before updating cache<ul> <li>Syntax check</li> <li>If there is any risk e.g. of vulnerability injection or vandalism, it can be mitigated with a signature check</li> </ul> </li> </ul> </li> </ul> </li> <li>Preferred format/serialization/syntax?<ul> <li>{Investigate}<ul> <li>Requirements:<ul> <li>allows comments</li> <li>can be validated (schema?)</li> <li>transformable</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"interoperability-and-portability/configuration/#interactive-management-eg-configurationadmin-panel","title":"Interactive management (e.g. configuration/admin panel)","text":"<ul> <li><code>&lt;to be filled in&gt;</code></li> </ul>"},{"location":"interoperability-and-portability/configuration/#links","title":"Links","text":"<ul> <li>https://12factor.net/config</li> </ul>"},{"location":"interoperability-and-portability/localisation/","title":"Localisation / internationaliszation","text":"<ul> <li>Application configuration</li> <li>Default locale</li> <li>Make locale configurable (?)Determining locale for client</li> <li>Respect browser setting</li> <li>User override (through UI)</li> <li>Don't use location for this!!</li> <li>Character set</li> <li>on provisioning, set server/host default encoding to UTF-8</li> <li>docker images: configure default encoding to UTF-8</li> <li>Applications: use UTF-8 explicitly</li> <li>Multilingual interfaces</li> <li>Does the interface have to be multilingual?<ul> <li>Only if content is also available in other languages</li> </ul> </li> <li>[insert link to articles about developer assumptions]</li> <li>UI testing<ul> <li>Very exotic Non-latin characters and diacritics (umlauts)</li> <li>Strings with variables inserted (order, split)</li> <li>Tests forms, error messages, generated strings<ul> <li>Also check:<ul> <li>numerical values (thousands and decimal separators)</li> <li>dates - pay attention to different renderings (long, short, month name, day of the week)</li> </ul> </li> </ul> </li> <li>Manual test with browser<ul> <li>Set browser to non-standard language/locale</li> </ul> </li> </ul> </li> <li>Use platform's framework</li> <li>Do it from the start</li> <li>Use this consistently<ul> <li>Don't use more different methods for defining string resources than necessary</li> </ul> </li> <li>Gotchas<ul> <li>{find online documentation for this}</li> <li>text direction; plural/singular; complex formatting (printf vs string concatenation)</li> </ul> </li> <li>Aligning application, frameworks/libraries and content localisation<ul> <li>Check that e.g. widgets don't do 'rogue' localisation</li> </ul> </li> <li>Writing direction<ul> <li>Where it's easy, be agnostic</li> <li>We don't design or test explicitly for different writing directions (only ltr)</li> </ul> </li> <li>Date and time</li> <li>date formats ISO 8601</li> <li>time zones, DST<ul> <li>explicit timezone</li> <li>on provisioning, set server/host timezone to UTC+0</li> <li>docker images: configure to explicitly set timezone to UTC+0 (part of init logic in base image)</li> </ul> </li> <li>&amp; logging<ul> <li>Always log date/time with timezone included</li> <li>Aim for using a single time zone across servers and applications</li> <li>Date/time format: configure ISO 8601</li> </ul> </li> </ul>"},{"location":"stack/bash/","title":"Bash","text":"<p>This section presents guidelines for the writing and maintenance of bash scripts.</p>"},{"location":"stack/bash/#general","title":"General","text":"<p>Automation of tasks, either locally or on our servers, should be implemented in Bash [^BASH] if possible.</p> <ul> <li>\ud83d\udc49 Any shell script <code>SHOULD</code> always be written in bash, using the following   shebang:</li> </ul> <pre><code>#!/usr/bin/env bash\n</code></pre> <p>Any task that has to be done more than once is a good candidate to automate with a shell script.</p> <p>Advantages:</p> <ul> <li>Supported on POSIX compatible OSes.</li> <li>Many developers and sysops are familiar with Bash:</li> <li>and thus standardizing on bash lowers the learning curve.</li> <li>and thus improving shareability.</li> <li>and thus improving the distributability over multiple people (i.e.      reducing the truck number).</li> </ul> <p>Disadvantages:</p> <ul> <li>Can become long and complex and thus harder to maintain.</li> </ul> <p>We leave it up to the developer / sysop to judge if and when a script becomes too long and too difficult to maintain. If implementing in Bash is not possible or considered not suitable it is possible to implement the task in a different language, preferably resulting in an executable binary which runs out-of-the-box without the need to install a runtime environment.</p>"},{"location":"stack/bash/#dependencies","title":"Dependencies","text":"<p>Scripts can make use of external dependencies to function properly. It is important to be aware of any missing dependencies before executing the scripts. Installing dependencies automatically from a script can have an impact on other processes running in the same environment and thus should be avoided where possible. The script should check for the availability of the dependencies during runtime and inform the user on how to proceed in case some dependency is missing.</p> <p>The use of subshells [^SUBSHELLS] is considered a good approach to isolate the effects of certain commands and operations.</p> <ul> <li>\ud83d\udc49 The script <code>MUST</code> not make any persistent changes to the environment where   it is executed. E.g. install packages.</li> <li>\ud83d\udc49 If the script depends on external tools, it <code>SHOULD</code> check if these   dependencies are available and abort execution of the script if any required   dependency is missing.</li> <li>\ud83d\udc49 If any required dependency is missing the script <code>SHOULD</code> print a warning   with a description on how to install the dependency.</li> </ul>"},{"location":"stack/bash/#code-style","title":"Code style","text":"<ul> <li>\ud83d\udc49 Scripts <code>SHOULD</code> be linted via the ShellCheck [^SHELLCHECK] utility.</li> <li>\ud83d\udc49 Hints <code>SHOULD</code> be considered and fixed where possible, however we aim to   be pragmatic and if needed a specific hint can be ignored.</li> </ul> <p>Google has a nice style guide [^GOOGLESTYLE] regarding shell scripts.</p> <p>Some important highlights from this guide:</p> <ul> <li>Always use .sh or .bash extension for shell scripts.</li> <li>Always add comment header below shebang with summary of script functionality.</li> <li>Line break before pipeline.</li> <li>Quote variables as <code>\"${foo}\"</code> instead of <code>$foo</code> and commands as <code>$(foo)</code>   instead of <code>foo</code>.</li> <li>Avoid <code>eval</code>.</li> <li>Write a <code>main</code> function for scripts longer than a few lines and/or other   functions and call it in the very end(i.e. last line) of the script, passing   all parameters: <code>main \"$@\"</code>.</li> <li>Calling scripts: use <code>bash script.sh</code> or <code>./script.sh</code> (not <code>sh script.sh</code>).</li> </ul> <p>Working directory assumptions:</p> <ul> <li>Do not make unnecessary assumptions about the current working directory,   particularly when calling other scripts. If the working directory is   important, specifically test for it and exit with a warning if there is any   issue.</li> <li>Never change the working directory, instead do work that required another   directory in a subshell only:</li> <li>Use round brackets to do work in a subshell: <code>( work )</code>.</li> </ul> <p>Checking if a variable is set:</p> <ul> <li>Just testing <code>-z ${var}</code> doesn\u2019t fail for the empty string <code>\"\"</code>. Instead use:</li> </ul> <pre><code>if [ -z ${var+x} ]; then echo \"var is unset\"; else echo \"var is set to '$var'\"; fi\n</code></pre> <p>as described in more detail in this [^STACKOVERFLOW] stackoverflow discussion.</p>"},{"location":"stack/bash/#documentation","title":"Documentation","text":"<ul> <li>\ud83d\udc49 Typically we <code>SHOULD</code> provide a comment directly after the shebang   describing the purpose of the script on a high level.</li> <li>\ud83d\udc49 Furthermore functions <code>SHOULD</code> have a short comment explaining the purpose   of the function, the support inputs and ouputs.</li> <li>\ud83d\udc49 A bash script <code>SHOULD</code> always support the <code>-h</code>, <code>--help</code> parameters. When   called with this argument the script gives a meaningful summary of its usage   and its parameters.</li> </ul>"},{"location":"stack/bash/#build-tools-continuous-integration","title":"Build tools &amp; Continuous Integration","text":"<p>When using the CLARIN build image [^BUILDIMAGE], ShellCheck linting can be enabled on gitlab.com [^GITLAB] as follows:</p> <ol> <li>Add a <code>lint</code> stage to the <code>stages</code> section.</li> <li>Add a command <code>shell-check</code> (or any other appropriate name) to the <code>lint</code>    stage with the script <code>./build.sh --lint-shell</code>.</li> </ol> <p>Example:</p> <pre><code>variables:\n    GIT_SUBMODULE_STRATEGY: recursive\n    DOCKER_DRIVER: overlay2\n    DOCKER_HOST: tcp://docker:2376\n    DOCKER_TLS_CERTDIR: \"/certs\"\n    DOCKER_TLS_VERIFY: 1\n    DOCKER_CERT_PATH: \"$DOCKER_TLS_CERTDIR/client\"\n\nimage: registry.gitlab.com/clarin-eric/build-image:1.3.4\nservices:\n- name: docker:20.10.21-dind\n...\nstages:\n- lint\n...\nshell-check:\n    stage: lint\n    script: timeout 1440 bash -x ./build.sh --lint-shell\n...\n</code></pre> <p>For github actions try this:</p> <pre><code>name: Shell linting\non:\n  push:\n  pull_request:\n\njobs:\n  lint:\n    name: Lint shell\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Lint\n        run: ./build.sh --lint-shell\n...\n</code></pre>"},{"location":"stack/bash/#testing-tools","title":"Testing tools","text":"<p>While advocating unit testing in general, we typically don't run unit tests for bash. A solution that has been mentioned is bash unit [^BASHUNIT], however we don't have experience with this tool.</p>"},{"location":"stack/bash/#static-code-analysis","title":"Static code analysis","text":"<p>Script analysis is achieved by linting via the ShellCheck[^SHELLCHECK] utility, see section above \"Build tools &amp; Continuous Integration\"</p>"},{"location":"stack/bash/#further-reading","title":"Further Reading","text":"<ul> <li>[^BASH] GNY Bash website</li> <li>[^SHELLCHECK] Shellcheck website</li> <li>[^SUBSHELLS] Advanced Bash-Scripting Guide: Chapter 21. Subshells</li> <li>[^GITLAB] Build Image GitLab repository</li> <li>[^BUILDIMAGE] Deploy Script GitLab repository</li> <li>[^STACKOVERFLOW]   Stackoverflow question: \"How to check if a variable is set in Bash\"</li> <li>[^BASHUNIT] bash_unit GitHub repository</li> <li>[^GOOGLESTYLE] Google Shell Style Guide</li> </ul>"},{"location":"stack/cython/","title":"Cython","text":""},{"location":"stack/docker/","title":"Docker","text":"<p>This section presents guidelines for the writing and maintenance of docker images.</p>"},{"location":"stack/docker/#general","title":"General","text":"<ul> <li>[x] TODO: discussion on application centered images vs use of environment   image (e.g. tomcat) and deploy application @ compose level</li> <li>[ ] Reference to operational section(s) on Docker (compose)</li> <li>[x] Docker version</li> <li>[x] Docker compose version</li> <li>[ ] Implementation of custom logic in compose project</li> <li>[ ] subcommands</li> <li>[ ] custom start/stop</li> <li>[ ] backup and restore</li> <li>[ ] Developing for use outside CLARIN infra context</li> <li>[ ] \"bundle\" control script submodule</li> <li>[x] Name for projects/repositories -&gt; image. TODO: discuss!</li> <li>[x] Strategy for base images</li> <li>[x] Strategy for application images</li> </ul> <p>Our applications and services are packed as container images, following the open container initiative (OCI) specification, using Docker. Ideally containers <code>SHOULD</code> run one process per container in the foreground. In practice this is not always easy depending on the situation. Newly developed services are more easy to fit into this model by taking this requirement into account from the design stage already. For existing services it can be more challenging to fit this model.</p> <p>For the CLARIN infrastructre we have created a set of base images, based on the alpine linux docker image, to provide an environment where we can more easily deploy existing services. These environments provide a supervisord daemon as the main process. The supervisord daemon [^SUPERVISORD] manages a couple of additional processes aimed at streamlining integration into our infrastructure. These processes are:</p> <ul> <li>td-agent [^TDAGENT], to tag and manage log output in the single stdout stream   of the container. Typically applications such as nginx, postgres, tomcat, etc   write multiple log files with different types of information. Td-agent allows   us to tag each of these streams so that these can be identified in the single   container stdout stream.</li> <li>cron [^CROND], a cron deamon to periodically run tasks inside the container.   This is used sparsely and might be removed at a later point in time.</li> <li>logrotate [^LOGROTATE], because we have processes running inside the container   that writes log data to files, we use the logrotate daemon to be able to   ensure log files are properly rotated and cleaned.</li> </ul>"},{"location":"stack/docker/#versions","title":"Versions","text":"<p>We are currently supporting the following versions:</p> <ul> <li>Docker engine version <code>20.10.x</code>.</li> <li>Docker compose yaml version <code>3.1</code>.</li> </ul> <p><code>TODO</code> Provide a link to the operational docker guidelines.</p>"},{"location":"stack/docker/#image-types-and-naming","title":"Image types and naming","text":""},{"location":"stack/docker/#base-images","title":"Base images","text":"<p>Any image providing some environment intended to be used by other images is considered a base image.</p> <p>Naming convention:</p> <pre><code>docker-&lt;base&gt;-&lt;name&gt;-base\n</code></pre> <p>Where:</p> <ul> <li><code>&lt;base&gt;</code> provides and indication of the underlying base image, typically   <code>alpine</code> for our base images.</li> <li><code>&lt;name&gt;</code>:  describes the main function of the image.</li> </ul> <p>Example: <code>docker-alpine-supervisor-base</code> as the name for the supervisor base image on alpine linux.</p> <p>Most important base images:</p> <ul> <li>docker-alpine-base</li> <li> <p>docker-alpine-supervisor-base</p> <ul> <li>docker-alpine-supervisor-java-base<ul> <li>docker-alpine-supervisor-java-tomcat-base</li> </ul> </li> <li>docker-alpine-fpm-base</li> </ul> </li> <li> <p>\ud83d\udc49 When developing a new image, you <code>SHOULD</code> base you image on the   <code>docker-alpine-supervisor-base</code> base image or any of its base image   descendants in most cases.</p> </li> </ul>"},{"location":"stack/docker/#regular-images","title":"Regular Images","text":"<p>All other images (images that are not a base image) are considered a regular image.</p> <p>Naming convention:</p> <pre><code>docker-&lt;name&gt;\n</code></pre> <p>Where:</p> <ul> <li><code>&lt;name&gt;</code>:  describes the main function of the image.</li> </ul> <p>Example: <code>docker-aai-discovery</code> as the name for the discovery service frontend image.</p>"},{"location":"stack/docker/#running-containers-from-images","title":"Running Containers from Images","text":"<p>Containers started from images that go together to offer a functional service, e.g. a frontend, backend and a database, are typically grouped into deployable projects via docker compose.</p> <ul> <li>\ud83d\udc49 (Compose) Projects are what we deploy and run on our infrastructure via the   CLARIN deploy script.</li> <li>\ud83d\udc49 These projects are started and stopped via the CLARIN control script.</li> </ul>"},{"location":"stack/docker/#code-style","title":"Code style","text":"<ul> <li>[ ] Dockerfiles</li> <li>[ ] CLARIN docker best practices<ul> <li>[ ] Use tag + digest for base image</li> <li>[ ] Differences from docker best practices<ul> <li>https://docs.docker.com/build/building/best-practices/</li> <li>https://docs.docker.com/get-started/09_image_best/</li> </ul> </li> </ul> </li> <li>[ ] Base images<ul> <li>[ ] For each main process<ul> <li>[ ] Supervisord setup</li> <li>[ ] Fluentd setup<ul> <li>[ ] See Logging</li> </ul> </li> <li>[ ] Logrotate setup</li> </ul> </li> <li>[ ] Default healthcheck<ul> <li>[ ] How to customise</li> </ul> </li> <li>[ ] Entrypoint<ul> <li>[ ] Supervisor base images</li> <li>[ ] Other cases</li> </ul> </li> <li>[ ] Initialisation logic</li> <li>[ ] \u2018Core\u2019 application directory<ul> <li>[ ] Choice of directory for stand-alone applications<ul> <li>[ ] If the environment or other context (e.g. tomcat) provides a    requirement or</li> </ul> </li> <li>[ ] guideline, follow that<ul> <li>[ ] If the choice is arbitrary, recommended locations follow OS conventions (typically alpine)</li> <li>[ ] for binaries</li> <li>[ ] /usr/local/bin</li> <li>[ ] for application bundles??</li> </ul> </li> <li>[ ] last WORKDIR in Dockerfile must be set to this directory</li> </ul> </li> </ul> </li> <li>[ ] Compose projects</li> <li>[ ] .env file/variables</li> <li>[ ] Overlays<ul> <li>[ ] Use cases</li> <li>[ ] When not to use -&gt; when variables can do the trick</li> <li>[ ] Custom scripts should hide complexity</li> </ul> </li> <li>[ ] Volumes &amp; networks<ul> <li>[ ] Internal &amp; external</li> </ul> </li> </ul>"},{"location":"stack/docker/#frameworks","title":"Frameworks","text":"<ul> <li>[ ] Build script</li> <li>[ ] https://gitlab.com/CLARIN-ERIC/build-script</li> <li>[ ] Testing</li> <li>[ ] images<ul> <li>[ ] Build script --test argument  with docker-compose</li> </ul> </li> <li>[ ] compose projects<ul> <li>[ ] test with ??</li> </ul> </li> </ul>"},{"location":"stack/docker/#documentation","title":"Documentation","text":"<ul> <li>[ ] Image project</li> <li>[ ] README<ul> <li>[ ] Reference base image</li> <li>[ ] List the important application and configuration locations (paths)   inside the</li> <li>[ ] image</li> <li>[ ] List the user name(s) defined and used in the image</li> </ul> </li> </ul>"},{"location":"stack/docker/#build-tools-continuous-integration","title":"Build tools &amp; Continuous Integration","text":"<ul> <li>[ ] Describe our gitlab CI integration with hadolint</li> <li>[ ] Include examples</li> <li>[ ] Gitlab Docker repository</li> </ul>"},{"location":"stack/docker/#testing-tools","title":"Testing tools","text":""},{"location":"stack/docker/#static-code-analysis","title":"Static code analysis","text":"<ul> <li>[ ] Linting with hadolint</li> <li>[ ] Security scanning</li> </ul>"},{"location":"stack/docker/#upstream-proxies","title":"Upstream proxies","text":"<p>Software projects (compose projects) should have an nginx in front of the application to work as the upstream server.  This is because we want:</p> <ol> <li>The upstreams to be uniform so that in the future we can deploy client /    server authentication between the proxy and the upstreams in a standard way.</li> <li>Non-standard webserver configurations that are specific to a certain    applications (e.g. SNI), will be deployed in the application project itself.    Avoiding split logic.</li> <li>The application should respond to all their requests on the same upstream    port. Again, wherever possible making the central proxy configuration    unaware  of the need for different ports.</li> </ol> <p>If possible this should apply to all applications meant to run behind our central proxy. (Maybe we can augment our compose project init code to add this nginx by default)</p> <p>There may be multiple nginx services in the same compose project as a result. One would be the dedicated proxy service. This is a desirable situation.</p> <ul> <li>[^SUPERVISORD] supervisord website</li> <li>[^TDAGENT] td-agent / fluentd website</li> <li>[^CROND] crond - Linux man page</li> <li>[^LOGROTATE] logrotate - Linux man page</li> </ul>"},{"location":"stack/java/","title":"Java","text":""},{"location":"stack/java/#general","title":"General","text":"<ul> <li>Java versions</li> <li>Recommended version -&gt; aligned with production. LTS?<ul> <li>https://www.oracle.com/java/technologies/java-se-support-roadmap.html</li> </ul> </li> <li>Vendor(s)<ul> <li>openjdk [Has to be supported by alpine, can change in the future]</li> </ul> </li> </ul>"},{"location":"stack/java/#code-style","title":"Code style","text":"<ul> <li>Formatting</li> <li>Following the Google Java Style Guide</li> <li>Any deviations??</li> <li>(Anti-)patterns</li> <li>TODO (requires reference &amp; motivation) [Guideline]<ul> <li>Exception handling<ul> <li>In relation to closeable objects</li> </ul> </li> <li>Use of interfaces</li> <li>Re-assigning variables (i.e. not final)</li> <li>Mutable collections</li> <li>Home brewing common but error prone algorithms<ul> <li>instead use library, typically guava</li> <li>examples: parsing (csv), string manipulations, IO pipelines, ...</li> </ul> </li> <li>...</li> </ul> </li> <li>Design considerations for applications and services</li> <li>OOP principles</li> </ul>"},{"location":"stack/java/#frameworks-libraries","title":"Frameworks &amp; libraries","text":"<p>Guideline: for each of the categories in the table below, investigate the applicability of the library listed in the respective \u2018guideline\u2019 column before considering alternatives or implementing your own utilities.</p> <p>Category</p> <p>Guideline\u00a0</p> <p>Remarks</p>          General utility:         Collections, Strings, IO, ..        <p> Guava           and/or           Apache Commons         </p> <p>Logging facade</p> <p>SLF4J</p> <p>Log binding</p> <p>logback</p> <p>           Log4j acceptable but considered legacy; migration to logback           recommended         </p> <p>CLI options</p> <p> Apache Commons CLI </p> <p>Dependency injection</p> <p>Spring IoC</p> <p>Use general Java annotation (e.g. @javax.inject.Inject)</p> <p>Web application (server side)</p> <p>Apache Wicket</p> <p>Spring (WebMVC, thymeleaf)</p> <p>Web service</p> <p>Dropwizard</p> <p>Spring (WebMVC / WebFlux)</p> <p>Testing</p> <p>JUnit</p> <p>Mocking</p> <p>Mockito</p> <p>XML testing</p> <p> XMLUnit </p>"},{"location":"stack/java/#documentation","title":"Documentation","text":"<ul> <li>Javadoc</li> <li>[Which guideline?]</li> <li>Publication</li> <li>What to put in README</li> <li>Java version</li> <li>Build instructions</li> </ul>"},{"location":"stack/java/#build-tools-continuous-integration","title":"Build tools &amp; Continuous Integration","text":"<ul> <li>Maven</li> <li>Project structure</li> <li>Versioning</li> <li>Deploying to repository<ul> <li>[Where to publish]</li> </ul> </li> <li>Gradle</li> <li>Don\u2019t use it [Guideline]</li> <li>Ant</li> <li>Definitely don\u2019t use it [Guideline]    -</li> </ul>"},{"location":"stack/java/#static-code-analysis","title":"Static code analysis","text":"<ul> <li>Maven plugins</li> <li>Code coverage</li> <li>Static code analysis</li> </ul>"},{"location":"stack/java/#further-reading","title":"Further reading","text":"<p>Recommended books, articles etc:</p> <p>Google Java Style Guide</p>"},{"location":"stack/javascript/","title":"Javascript","text":""},{"location":"stack/python/","title":"Python","text":""},{"location":"stack/python/#general","title":"General","text":"<p>PEP is a set of Python community guidelines that is a baseline for our guidelines. If you adhere to explicit PEP you can't go wrong, however as it is possible for PEPs to clash with one other we explicitly state preferred standards further. Note, that in the following sections <code>Python</code> refers explicitly to <code>Python3</code>. <code>Python2</code> reached EOL on 1.01.2020. At CLARIN-ERIC we do not operate any legacy <code>Python2</code> software and no new developments will take place, therefor we omit it in this chapter.</p>"},{"location":"stack/python/#scope-of-guidelines-applicability","title":"Scope of guidelines applicability","text":"<p>Automation of tasks can be conducted using Python, but we highly recommend using Bash as a default scripting language. However, it may be beneficial to use Python in certain applications, e.g. educational content, data manipulation, data visualisation, etc., where the outcome is knowledge not software. We do not impose any explicit requirements and guidelines on Python for non-software code. It is up to the programmer to wage pros and cons of automation using Python in a given context, to be aware of target group and adjust programming practices to the context in which they are applied. Following these guidelines is a <code>MUST</code> only for software meant for deployment in production.</p>"},{"location":"stack/python/#environment","title":"Environment","text":"<ul> <li>\ud83d\udc49 <code>MUST</code> use latest Python supported by all other dependencies.</li> <li>\ud83d\udc49 <code>MUST NOT</code> use your default Python distribution for development environment if your OS comes with one as it can brake system packages dependent on Python.</li> <li>\ud83d\udc49 <code>MUST NOT</code> override your default OS Python.</li> <li>\ud83d\udc49 <code>MUST NOT</code> alter your default <code>python/python3</code></li> <li>\ud83d\udc49 <code>MUST</code> use virtual environment manager. Recommended lightweight core Venv or Anaconda.</li> </ul>"},{"location":"stack/python/#code-style","title":"Code style","text":"<ul> <li>\ud83d\udc49 <code>MUST</code> enforce consistent design choices within each self-standing software/package</li> <li>\ud83d\udc49 <code>MUST</code> follow PEP8 guidelines on code styling</li> <li>\ud83d\udc49 <code>MUST</code> strive for highest possible static type hint coverage whenever reasonably possible PEP484</li> <li>\u2003(if framework documentation doesn't expose the types or uses <code>x: Any</code> you are excused)</li> <li>\ud83d\udc49 <code>MUST</code> strive for highest possible duck type hint coverage PEP544</li> <li>\u2003(if framework documentation doesn't expose the protocols or uses <code>x: Any</code> you are excused)</li> <li>\ud83d\udc49 <code>MUST</code> follow minimal docstring conventions PEP257</li> <li>\ud83d\udc49 <code>SHOULD</code> use Sphinx docstring syntax. Any other well-defined convention is acceptable, but Sphinx is preferred. Remember to maintain consistant conventions within self-contained packages.</li> </ul>"},{"location":"stack/python/#frameworks-libraries","title":"Frameworks &amp; libraries","text":"<p>List of recommended packages for specific applications.</p>"},{"location":"stack/python/#django","title":"Django","text":"<p>We currently use Django for MVC apps. Always strive for latest LTS Django support.</p>"},{"location":"stack/python/#django-rest-framework","title":"Django REST framework","text":"<p>We currently use Django-rest-framework for REST API implementation. Other non-Django solutions like Flask are also fine, but we have no experience in working with any of them. Developers are free to explore other options.</p>"},{"location":"stack/python/#xml-processing","title":"XML processing","text":"<p>For <code>XML</code> files processing <code>SHOULD</code> use lxml.</p>"},{"location":"stack/python/#logging","title":"Logging","text":"<p>By default, <code>SHOULD</code> use Python's core logging package. Django logging utilises core Python logging making it fully compatible.</p>"},{"location":"stack/python/#building-and-deployment","title":"Building and deployment","text":""},{"location":"stack/python/#build","title":"Build","text":"<p>Use <code>pip</code> as default package manage:</p> <ul> <li>\ud83d\udc49 <code>MUST</code> build wheels and install package from the wheel PEP427.</li> <li>\ud83d\udc49 <code>MUST</code> use pytoml + <code>SHOULD</code> use Poetry as SCM backend</li> <li>\ud83d\udc49 <code>MUST</code> distribute packages as wheels</li> <li>\ud83d\udc49 <code>MUST</code> use CLARIN's wheel builder for building wheels</li> </ul>"},{"location":"stack/python/#testing","title":"Testing","text":"<ul> <li>\ud83d\udc49 Yes \ud83d\uddff</li> <li>\ud83d\udc49 The more tests the better.</li> <li>\ud83d\udc49 Strive for full unit test coverage</li> </ul>"},{"location":"stack/python/#testing-tools","title":"Testing tools","text":"<p>List of recommended testing tools</p>"},{"location":"stack/python/#unittests","title":"Unittests","text":"<ul> <li>Python's core unittest</li> <li>Django's unittest extension</li> <li>Django-rest-framework unittest extension</li> </ul>"},{"location":"stack/python/#todo-selenium-and-integration-testing","title":"TODO selenium and integration testing","text":""},{"location":"stack/python/#common-beginners-mistakes","title":"Common beginner's mistakes","text":"<ul> <li>\ud83d\udc49 <code>MUST NOT</code> use mutable default parameters values in functions, unless having a very good reason to do so. (explicitly and exhaustively document its usage with rationale for such design choice):</li> </ul> <pre><code>\"\"\"\nDefault parameter value is evaluated on function definition,\neach call to function mutating the parameter will mutate the default value.\n\nRead more: https://docs.python-guide.org/writing/gotchas/.\n\"\"\"\n\n# DO\ndef (param: List = None):\n    param = []\n    pass\n\n# DO NOT\ndef (param: List = []):\n    pass\n</code></pre>"}]}